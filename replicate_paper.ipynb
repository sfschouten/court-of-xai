{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Attention is Consistent with Feature Importance\n",
    "\n",
    "A simple notebook for reproducing our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import logging\n",
    "from ane_research.config import Config\n",
    "from ane_research.utils.logger import initialize_logger\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# clear any logging relics\n",
    "reload(logging)\n",
    "logger = initialize_logger(Config.logger_name, in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Run All Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ane_research.utils.experiments import run_all_experiments_in_dir\n",
    "\n",
    "experiments = run_all_experiments_in_dir('experiments')\n",
    "for experiment in experiments:\n",
    "    graphs = experiment.get_figure_paths()\n",
    "    for graph in graphs:\n",
    "        display(Image(filename=graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Run Specific Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ane_research.utils.experiments import run_experiment\n",
    "\n",
    "# Edit as necessary - These are the 8 runs we performed in the paper\n",
    "experiments_list = [\n",
    "    'experiments/sst_tanh_sparsemax.jsonnet',\n",
    "    'experiments/sst_tanh_softmax.jsonnet',\n",
    "    'experiments/sst_sdp_sparsemax.jsonnet',\n",
    "    'experiments/sst_sdp_softmax_jsonnet',\n",
    "    'experiments/imdb_tanh_sparsemax.jsonnet',\n",
    "    'experiments/imdb_tanh_softmax.jsonnet',\n",
    "    'experiments/imdb_sdp_sparsemax.jsonnet',\n",
    "    'experiments/imdb_sdp_softmax_jsonnet',\n",
    "]\n",
    "\n",
    "for experiment_file in experiments_list:\n",
    "    experiment = run_experiment(experiment_file)\n",
    "    graphs = experiment.get_figure_paths()\n",
    "    for graph in graphs:\n",
    "        # These graphs are big!\n",
    "        display(Image(filename=graph))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import numbers\n",
    "import scipy.stats as stats\n",
    "import scipy.special as special\n",
    "from typing import Any, Tuple\n",
    "\n",
    "def kendall_top_k(a: Any, b: Any, k: int = None, kIsNonZero: bool = False, p: float = 0.5) -> Tuple[float, int]:\n",
    "    \"\"\"Compute the top-k kendall-tau correlation metric for the given ranked lists.\n",
    "    Args:\n",
    "        a (ArrayLike):\n",
    "            The first ranked list. Can be any array-like type (e.g. list, numpy array or cpu-bound tensor)\n",
    "        b (ArrayLike):\n",
    "            The second ranked list. Can be any array-like type (e.g. list, numpy array or cpu-bound tensor)\n",
    "        k (int, optional):\n",
    "            Only the top \"k\" elements are compared. Defaults to the size of the first list\n",
    "        kIsNonZero (bool, optional):\n",
    "            If specified, overrides k to be the minimum number of non-zero elements in either list. Defaults to False\n",
    "        p (float, optional):\n",
    "            The penalty parameter in the range [0, 1]. Defaults to the neutral case, p = 0.5\n",
    "    Raises:\n",
    "        ValueError: If p is not defined as described or if the lists are not equal in length\n",
    "    Returns:\n",
    "        Tuple[float, int]: A tuple of the computed correlation and the value used for k\n",
    "    \"\"\"\n",
    "    if not (isinstance(p, numbers.Real) and p >= 0 and p <= 1):\n",
    "        raise ValueError(\"The penalty parameter p must be numeric and in the range [0,1]\")\n",
    "\n",
    "    x = np.array(a).flatten()\n",
    "    y = np.array(b).flatten()\n",
    "\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"The ranked lists must have same lengths\")\n",
    "\n",
    "    if kIsNonZero:\n",
    "        k = min(np.count_nonzero(x), np.count_nonzero(y))\n",
    "    elif k is None:\n",
    "        k = x.size\n",
    "\n",
    "    k = min(k, x.size)\n",
    "\n",
    "    # indices of the top k arguments e.g., [1, 2, 3, 4] with k = 3 --> [1, 2 ,3]\n",
    "    x_top_k = np.argpartition(x, -k)[-k:]\n",
    "    # ranks of all arguments (projection from a list onto the domain [1...n]) e.g., [55, 42, 89, 100] --> [3, 4, 2, 1]\n",
    "    x_ranks = np.full(x.size, x.size + 1) - stats.rankdata(x)\n",
    "\n",
    "    y_top_k = np.argpartition(y, -k)[-k:]\n",
    "    y_ranks = np.full(y.size, y.size + 1) - stats.rankdata(y)\n",
    "\n",
    "    print(x_ranks)\n",
    "    print(y_ranks)\n",
    "    \n",
    "    # Using the explicit notation of Fagin et al. with references to their equation numbers\n",
    "    Z = np.intersect1d(x_top_k, y_top_k)\n",
    "    S = np.setdiff1d(x_top_k, y_top_k)\n",
    "    T = np.setdiff1d(y_top_k, x_top_k)\n",
    "    z = Z.size\n",
    "    print(Z)\n",
    "    print(S)\n",
    "    print(T)\n",
    "\n",
    "    # Equation 1: i and j appear in both top k lists. Penalize per the number of shared pairs that are discordant\n",
    "    # Code partially taken from scipy.stats.kendalltau\n",
    "    rx, ry = x[Z], y[Z]\n",
    "    eqn1 = np.sum([((ry[i + 1:] < ry[i]) * (rx[i + 1:] > rx[i])).sum() for i in range(len(ry) - 1)], dtype=float)\n",
    "\n",
    "    # Equation 2: i and j both appear in one top k list, and exactly one of i or j appears in the other\n",
    "    eqn2 = (k - z) * (k + z + 1) - sum(x_ranks[S]) - sum(y_ranks[T])\n",
    "    \n",
    "    assert (not k == z) or eqn2 == 0\n",
    "    \n",
    "    # Equation 3: i, but not j, appears in one top k list and j, but not i, appears in the other\n",
    "    eqn3 = (k - z) ** 2\n",
    "\n",
    "    assert (not k == z) or eqn3 == 0\n",
    "    \n",
    "    # Equation 4: i and j both appear in one top k list, but neither i nor j appears in the other\n",
    "    eqn4 = 2 * p * special.comb(k - z, 2)\n",
    "\n",
    "    assert (not k == z) or eqn4 == 0\n",
    "    \n",
    "    kendall_distance_with_penalty = eqn1 + eqn2 + eqn3 + eqn4\n",
    "\n",
    "    # Normalize the distance to a correlation in the range [-1, 1]\n",
    "    correlation = kendall_distance_with_penalty / special.comb(S.size + T.size + z, 2)\n",
    "    correlation *= -2\n",
    "    correlation += 1\n",
    "\n",
    "    return (correlation, k)\n",
    "    \n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "    \n",
    "a = [0.00924963, 0.04445712, 0.02014468, 0.04744543, 0.01616605, 0.03727183,\n",
    " 0.02536283, 0.02776813, 0.01844794, 0.10662094, 0.10609859, 0.0161676,\n",
    " 0.16745505, 0.02182889, 0.02090209, 0.00257502, 0.03120976, 0.03747579,\n",
    " 0.00226188, 0.01272965, 0.00909619]\n",
    "b = [0.00896137, 0.05222384, 0.02614146, 0.05706653, 0.01223692, 0.05689022,\n",
    " 0.03800762, 0.03169076, 0.01273555, 0.14963414, 0.13315924, 0.02639366,\n",
    " 0.26344773, 0.03380115, 0.02689381, 0.01485158, 0.0552543,  0.06618203,\n",
    " 0.01013477, 0.02311206, 0.01089478]\n",
    "\n",
    "a = [18, 5, 13, 4, 16, 7, 10, 9, 14, 2, 3, 15, 1, 11, 12, 20,  8,  6, 21, 17, 19]\n",
    "b = [21, 8, 14, 5, 18, 6, 9, 11, 17, 2, 3, 13, 1, 10, 12, 16,  7,  4, 20, 15, 19]\n",
    "\n",
    "k = len(a)\n",
    "assert len(a) == len(b)\n",
    "\n",
    "print(kendall_top_k(a, b, k=k))\n",
    "print(kendalltau(a, b, nan_policy='propagate'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
